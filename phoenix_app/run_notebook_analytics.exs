#!/usr/bin/env elixir

# Livebook Notebook Analytics Runner
# Executes the core analytics from the Livebook notebooks as standalone scripts

Mix.install([
  {:jason, "~> 1.4"},
  {:req, "~> 0.5.0"}
])

defmodule NotebookAnalytics do
  @moduledoc """
  Standalone execution of Livebook notebook analytics.
  Runs the core data analysis and visualization logic without Livebook UI.
  """

  def run_telemetry_analysis do
    IO.puts("ðŸ” Running Telemetry Analysis...")
    
    # Simulate telemetry data collection
    telemetry_data = %{
      timestamp: DateTime.utc_now(),
      events: generate_mock_telemetry_events(),
      system_metrics: get_system_metrics()
    }
    
    # Analysis
    analysis = analyze_telemetry_data(telemetry_data)
    
    # Output results
    IO.puts("ðŸ“Š Telemetry Analysis Results:")
    IO.puts("  â€¢ Total Events: #{length(telemetry_data.events)}")
    IO.puts("  â€¢ Memory Usage: #{analysis.memory_mb} MB")
    IO.puts("  â€¢ Process Count: #{analysis.process_count}")
    IO.puts("  â€¢ Health Status: #{analysis.health_status}")
    
    save_results("telemetry_analysis", analysis)
    analysis
  end

  def run_coordination_analysis do
    IO.puts("ðŸ¤ Running Agent Coordination Analysis...")
    
    # Load coordination data
    coordination_data = %{
      agents: load_agent_status(),
      work_claims: load_work_claims(),
      coordination_log: load_coordination_log()
    }
    
    # Analysis
    analysis = analyze_coordination_efficiency(coordination_data)
    
    # Output results
    IO.puts("ðŸ“Š Coordination Analysis Results:")
    IO.puts("  â€¢ Active Agents: #{analysis.active_agents}")
    IO.puts("  â€¢ Work Items: #{analysis.active_work_items}")
    IO.puts("  â€¢ Efficiency: #{analysis.efficiency_score}%")
    IO.puts("  â€¢ Recommendations: #{length(analysis.recommendations)}")
    
    Enum.each(analysis.recommendations, fn rec ->
      IO.puts("    - #{rec}")
    end)
    
    save_results("coordination_analysis", analysis)
    analysis
  end

  def run_performance_analysis do
    IO.puts("ðŸš€ Running Performance Analysis...")
    
    # Collect performance data
    performance_data = %{
      memory_usage: :erlang.memory(),
      process_count: :erlang.system_info(:process_count),
      reductions: elem(:erlang.statistics(:reductions), 0),
      run_queue: :erlang.statistics(:run_queue),
      io_stats: :erlang.statistics(:io)
    }
    
    # Analysis
    analysis = analyze_performance_metrics(performance_data)
    
    # Output results
    IO.puts("ðŸ“Š Performance Analysis Results:")
    IO.puts("  â€¢ Overall Score: #{analysis.performance_score}/100")
    IO.puts("  â€¢ Memory Grade: #{analysis.memory_grade}")
    IO.puts("  â€¢ CPU Grade: #{analysis.cpu_grade}")
    IO.puts("  â€¢ Bottlenecks: #{length(analysis.bottlenecks)}")
    
    Enum.each(analysis.bottlenecks, fn bottleneck ->
      IO.puts("    - #{bottleneck}")
    end)
    
    save_results("performance_analysis", analysis)
    analysis
  end

  def run_ai_improvement_analysis do
    IO.puts("ðŸ¤– Running AI Improvement Analysis...")
    
    # Mock AI improvement data
    ai_data = %{
      improvements: generate_mock_improvements(),
      metrics: generate_mock_metrics(),
      success_rate: 85.6
    }
    
    # Analysis
    analysis = analyze_ai_improvements(ai_data)
    
    # Output results
    IO.puts("ðŸ“Š AI Improvement Analysis Results:")
    IO.puts("  â€¢ Total Improvements: #{length(ai_data.improvements)}")
    IO.puts("  â€¢ Success Rate: #{ai_data.success_rate}%")
    IO.puts("  â€¢ Top Categories: #{Enum.join(analysis.top_categories, ", ")}")
    IO.puts("  â€¢ Trend: #{analysis.trend}")
    
    save_results("ai_improvement_analysis", analysis)
    analysis
  end

  def run_comprehensive_report do
    IO.puts("ðŸ“‹ Generating Comprehensive System Report...")
    
    # Run all analyses
    telemetry = run_telemetry_analysis()
    coordination = run_coordination_analysis()
    performance = run_performance_analysis()
    ai_improvements = run_ai_improvement_analysis()
    
    # Generate comprehensive report
    report = %{
      timestamp: DateTime.utc_now(),
      system_health: %{
        overall_score: calculate_overall_score([telemetry, coordination, performance, ai_improvements]),
        telemetry: telemetry.health_status,
        coordination: coordination.efficiency_score,
        performance: performance.performance_score,
        ai_improvements: ai_improvements.trend
      },
      summary: %{
        total_agents: coordination.active_agents,
        memory_usage_mb: telemetry.memory_mb,
        process_count: telemetry.process_count,
        success_rate: ai_improvements.trend,
        recommendations: generate_system_recommendations([telemetry, coordination, performance, ai_improvements])
      }
    }
    
    IO.puts("\nðŸŽ¯ COMPREHENSIVE SYSTEM REPORT")
    IO.puts("=" |> String.duplicate(50))
    IO.puts("Overall Health Score: #{report.system_health.overall_score}/100")
    IO.puts("System Status: #{get_status_emoji(report.system_health.overall_score)}")
    IO.puts("\nKey Metrics:")
    IO.puts("  â€¢ Active Agents: #{report.summary.total_agents}")
    IO.puts("  â€¢ Memory Usage: #{report.summary.memory_usage_mb} MB")
    IO.puts("  â€¢ Process Count: #{report.summary.process_count}")
    IO.puts("\nTop Recommendations:")
    
    Enum.take(report.summary.recommendations, 5)
    |> Enum.with_index(1)
    |> Enum.each(fn {rec, idx} ->
      IO.puts("  #{idx}. #{rec}")
    end)
    
    save_results("comprehensive_report", report)
    report
  end

  # Private helper functions

  defp generate_mock_telemetry_events do
    1..50
    |> Enum.map(fn i ->
      %{
        timestamp: DateTime.add(DateTime.utc_now(), -i * 60, :second),
        event: [:self_sustaining, :reactor, :execution, :complete],
        measurements: %{
          duration: :rand.uniform(1000) + 100,
          memory: :rand.uniform(50_000_000) + 10_000_000
        },
        metadata: %{
          reactor_id: "reactor_#{:rand.uniform(10)}",
          success: :rand.uniform() > 0.1
        }
      }
    end)
  end

  defp get_system_metrics do
    %{
      memory_usage: :erlang.memory(),
      process_count: :erlang.system_info(:process_count),
      timestamp: DateTime.utc_now()
    }
  end

  defp analyze_telemetry_data(data) do
    memory_mb = data.system_metrics.memory_usage[:total] / 1024 / 1024
    
    %{
      memory_mb: Float.round(memory_mb, 2),
      process_count: data.system_metrics.process_count,
      event_count: length(data.events),
      avg_duration: calculate_avg_duration(data.events),
      health_status: if(memory_mb < 500 and data.system_metrics.process_count < 50000, do: "healthy", else: "attention_needed")
    }
  end

  defp calculate_avg_duration(events) do
    if length(events) > 0 do
      total = Enum.sum(Enum.map(events, &(&1.measurements.duration)))
      Float.round(total / length(events), 2)
    else
      0
    end
  end

  defp load_agent_status do
    # Read from actual file if exists, otherwise return mock data
    case File.read(".agent_coordination/agent_status.json") do
      {:ok, content} ->
        case Jason.decode(content) do
          {:ok, data} -> data
          _ -> generate_mock_agent_status()
        end
      _ -> generate_mock_agent_status()
    end
  end

  defp load_work_claims do
    case File.read(".agent_coordination/work_claims.json") do
      {:ok, content} ->
        case Jason.decode(content) do
          {:ok, data} when is_list(data) ->
            # Convert list to map for compatibility
            data |> Enum.with_index() |> Enum.into(%{}, fn {item, idx} -> {to_string(idx), item} end)
          {:ok, data} when is_map(data) -> data
          _ -> %{}
        end
      _ -> %{}
    end
  end

  defp load_coordination_log do
    case File.read(".agent_coordination/coordination_log.json") do
      {:ok, content} ->
        case Jason.decode(content) do
          {:ok, data} -> data
          _ -> []
        end
      _ -> []
    end
  end

  defp generate_mock_agent_status do
    1..5
    |> Enum.map(fn i ->
      agent_id = "agent_#{System.system_time(:nanosecond) + i}"
      {agent_id, %{
        "status" => Enum.random(["active", "idle", "busy"]),
        "work_items_claimed" => :rand.uniform(5),
        "work_items_completed" => :rand.uniform(10),
        "team" => "team_#{:rand.uniform(3)}",
        "last_activity" => DateTime.utc_now() |> DateTime.to_string()
      }}
    end)
    |> Enum.into(%{})
  end

  defp analyze_coordination_efficiency(data) do
    active_agents = map_size(data.agents)
    active_work = map_size(data.work_claims)
    completed_work = length(data.coordination_log)
    
    efficiency_score = if active_agents > 0 do
      Float.round((completed_work + active_work) / active_agents * 20, 1)
    else
      0
    end
    
    recommendations = generate_coordination_recommendations(active_agents, active_work, efficiency_score)
    
    %{
      active_agents: active_agents,
      active_work_items: active_work,
      completed_work_items: completed_work,
      efficiency_score: efficiency_score,
      recommendations: recommendations
    }
  end

  defp generate_coordination_recommendations(agents, work, efficiency) do
    recommendations = []
    
    recommendations = if efficiency < 50 do
      ["Improve work distribution efficiency" | recommendations]
    else
      recommendations
    end
    
    recommendations = if agents == 0 do
      ["No active agents detected - check agent startup" | recommendations]
    else
      recommendations
    end
    
    recommendations = if work > agents * 5 do
      ["Work overload detected - consider adding more agents" | recommendations]
    else
      recommendations
    end
    
    if length(recommendations) == 0 do
      ["System coordination is operating efficiently"]
    else
      recommendations
    end
  end

  defp analyze_performance_metrics(data) do
    memory_mb = data.memory_usage[:total] / 1024 / 1024
    
    # Calculate performance score
    memory_score = if memory_mb < 500, do: 100, else: max(0, 100 - (memory_mb - 500) / 10)
    process_score = if data.process_count < 50000, do: 100, else: max(0, 100 - (data.process_count - 50000) / 1000)
    
    performance_score = Float.round((memory_score + process_score) / 2, 1)
    
    bottlenecks = []
    bottlenecks = if memory_mb > 1000, do: ["High memory usage detected" | bottlenecks], else: bottlenecks
    bottlenecks = if data.process_count > 75000, do: ["High process count detected" | bottlenecks], else: bottlenecks
    bottlenecks = if data.run_queue > 10, do: ["CPU overload detected" | bottlenecks], else: bottlenecks
    
    %{
      performance_score: performance_score,
      memory_grade: get_grade(memory_score),
      cpu_grade: get_grade(process_score),
      bottlenecks: if(length(bottlenecks) == 0, do: ["No significant bottlenecks detected"], else: bottlenecks)
    }
  end

  defp get_grade(score) when score >= 90, do: "A"
  defp get_grade(score) when score >= 80, do: "B"
  defp get_grade(score) when score >= 70, do: "C"
  defp get_grade(score) when score >= 60, do: "D"
  defp get_grade(_), do: "F"

  defp generate_mock_improvements do
    1..20
    |> Enum.map(fn i ->
      %{
        id: i,
        type: Enum.random(["performance", "security", "functionality", "optimization"]),
        status: Enum.random(["completed", "pending", "in_progress"]),
        confidence: :rand.uniform(),
        created_at: DateTime.add(DateTime.utc_now(), -i * 3600, :second)
      }
    end)
  end

  defp generate_mock_metrics do
    1..100
    |> Enum.map(fn i ->
      %{
        metric_type: Enum.random(["latency", "throughput", "error_rate", "memory_usage"]),
        value: :rand.uniform(100),
        timestamp: DateTime.add(DateTime.utc_now(), -i * 60, :second)
      }
    end)
  end

  defp analyze_ai_improvements(data) do
    completed = Enum.count(data.improvements, &(&1.status == "completed"))
    total = length(data.improvements)
    
    type_counts = Enum.frequencies(Enum.map(data.improvements, & &1.type))
    top_categories = type_counts |> Enum.sort_by(&elem(&1, 1), :desc) |> Enum.take(3) |> Enum.map(&elem(&1, 0))
    
    trend = cond do
      data.success_rate > 80 -> "excellent"
      data.success_rate > 60 -> "good"
      data.success_rate > 40 -> "fair"
      true -> "needs_attention"
    end
    
    %{
      total_improvements: total,
      completed_improvements: completed,
      success_rate: if(total > 0, do: Float.round(completed / total * 100, 1), else: 0),
      top_categories: top_categories,
      trend: trend
    }
  end

  defp calculate_overall_score(analyses) do
    ai_trend = analyses |> Enum.at(3) |> Map.get(:trend)
    
    scores = [
      if(analyses |> Enum.at(0) |> Map.get(:health_status) == "healthy", do: 90, else: 60),
      analyses |> Enum.at(1) |> Map.get(:efficiency_score, 70),
      analyses |> Enum.at(2) |> Map.get(:performance_score, 70),
      if(ai_trend in ["excellent", "good"], do: 85, else: 65)
    ]
    
    Float.round(Enum.sum(scores) / length(scores), 1)
  end

  defp generate_system_recommendations(analyses) do
    recommendations = []
    
    # From telemetry analysis
    telemetry = Enum.at(analyses, 0)
    recommendations = if telemetry.health_status != "healthy" do
      ["Monitor system resource usage closely" | recommendations]
    else
      recommendations
    end
    
    # From coordination analysis
    coordination = Enum.at(analyses, 1)
    recommendations = recommendations ++ coordination.recommendations
    
    # From performance analysis
    performance = Enum.at(analyses, 2)
    recommendations = recommendations ++ performance.bottlenecks
    
    # From AI improvements
    ai = Enum.at(analyses, 3)
    recommendations = if ai.trend == "needs_attention" do
      ["Review AI improvement processes for optimization" | recommendations]
    else
      recommendations
    end
    
    recommendations
    |> Enum.uniq()
    |> Enum.take(10)
  end

  defp get_status_emoji(score) when score >= 90, do: "ðŸŸ¢ Excellent"
  defp get_status_emoji(score) when score >= 75, do: "ðŸŸ¡ Good"
  defp get_status_emoji(score) when score >= 60, do: "ðŸŸ  Fair" 
  defp get_status_emoji(_), do: "ðŸ”´ Needs Attention"

  defp save_results(analysis_type, data) do
    timestamp = DateTime.utc_now() |> DateTime.to_iso8601() |> String.replace(":", "_")
    filename = "#{analysis_type}_#{timestamp}.json"
    
    case Jason.encode(data, pretty: true) do
      {:ok, json} ->
        File.write!(filename, json)
        IO.puts("ðŸ’¾ Results saved to #{filename}")
      {:error, _} ->
        IO.puts("âŒ Failed to save results")
    end
  end
end

# Main execution
case System.argv() do
  ["telemetry"] -> NotebookAnalytics.run_telemetry_analysis()
  ["coordination"] -> NotebookAnalytics.run_coordination_analysis()
  ["performance"] -> NotebookAnalytics.run_performance_analysis()
  ["ai"] -> NotebookAnalytics.run_ai_improvement_analysis()
  ["all"] -> NotebookAnalytics.run_comprehensive_report()
  [] -> NotebookAnalytics.run_comprehensive_report()
  _ ->
    IO.puts("""
    ðŸ“Š Livebook Notebook Analytics Runner
    
    Usage: elixir run_notebook_analytics.exs [analysis_type]
    
    Available analysis types:
      telemetry     - Real-time telemetry analysis
      coordination  - Agent coordination efficiency
      performance   - System performance metrics
      ai            - AI improvement analysis
      all           - Comprehensive system report (default)
    
    Examples:
      elixir run_notebook_analytics.exs
      elixir run_notebook_analytics.exs telemetry
      elixir run_notebook_analytics.exs all
    """)
end